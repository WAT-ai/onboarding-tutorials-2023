{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath = \"/Users/trevoryu/Code/data/FOG_data/002/task_1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all the columns more pythonically\n",
    "patient_emg_columns = {\n",
    "    \"001\": [\"emg_right_ta\", \"emg_left_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"002\": [\"emg_right_ta\", \"emg_left_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"003\": [\"emg_left_ta\", \"emg_right_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"004\": [\"emg_left_ta\", \"emg_right_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"005\": [\"emg_left_ta\", \"emg_right_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"006\": [\"emg_right_ta\", \"emg_left_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"007\": [\"emg_right_ta\", \"emg_left_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"008/OFF_1\": [\"emg_right_ta\", \"emg_left_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"008/OFF_2\": [\"emg_right_ta\", \"emg_right_gs\", \"eog\", \"ecg\", \"emg_left_ta\"],\n",
    "    \"009\": [\"emg_left_ta\", \"emg_right_ta\", \"eog\", \"emg_right_gs\", \"ecg\"],\n",
    "    \"010\": [\"emg_left_ta\", \"emg_right_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"011\": [\"emg_left_ta\", \"emg_right_ta\", \"eog\", \"ecg\", \"emg_right_gs\"],\n",
    "    \"012\": [\"emg_left_ta\", \"emg_right_ta\", \"eog\", \"ecg\", \"emg_right_gs\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make names for other columns\n",
    "a = [\"left_shank\", \"right_shank\", \"waist\", \"arm\"]\n",
    "b = [\"accel_x\", \"accel_y\", \"accel_z\", \"gyro_x\", \"gyro_y\", \"gyro_z\", \"NC\"]\n",
    "imu_options = [\"_\".join(x) for x in itertools.product(a, b)]\n",
    "# Only arm is SC\n",
    "imu_options[-1] = \"arm_skin_conductance\"\n",
    "\n",
    "eeg_columns = [\n",
    "    \"FP1\", \"FP2\", \"F3\", \"F4\",\n",
    "    \"C4\", \"C5\", \"P3\", \"P4\",\n",
    "    \"O1\", \"O2\", \"F7\", \"F8\", \"P7\", \"P8\", \"FZ\",\n",
    "    \"CZ\", \"PZ\", \"FC1\", \"FC2\", \"CP1\", \"CP2\", \"FC5\", \"FC6\", \"CP5\", \"CP6\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant data columns in specific order\n",
    "cols = [\n",
    "    \"timestamp\",\n",
    "    \"labels\",\n",
    "    # EMG signals\n",
    "    'emg_right_ta', 'emg_left_ta', 'emg_right_gs',\n",
    "    'ecg', 'eog',\n",
    "    # IMU L-Shank\n",
    "    'left_shank_accel_x', 'left_shank_accel_y', 'left_shank_accel_z',\n",
    "    'left_shank_gyro_x', 'left_shank_gyro_y', 'left_shank_gyro_z',\n",
    "    # IMU R-Shank\n",
    "    'right_shank_accel_x', 'right_shank_accel_y', 'right_shank_accel_z',\n",
    "    'right_shank_gyro_x', 'right_shank_gyro_y', 'right_shank_gyro_z',\n",
    "    # IMU waist\n",
    "    'waist_accel_x', 'waist_accel_y', 'waist_accel_z',\n",
    "    'waist_gyro_x', 'waist_gyro_y', 'waist_gyro_z',\n",
    "    # IMU arm\n",
    "    'arm_accel_x', 'arm_accel_y', 'arm_accel_z',\n",
    "    'arm_gyro_x', 'arm_gyro_y', 'arm_gyro_z',\n",
    "    # Arm skin conductance\n",
    "    'arm_skin_conductance'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the files and turn into dataframe\n",
    "data_files = glob.glob(\"/Users/trevoryu/Code/data/FOG_data/*/*.txt\")\n",
    "data_files = data_files + glob.glob(\"/Users/trevoryu/Code/data/FOG_data/*/*/*.txt\")  # subject 008 has extra directory\n",
    "data_files = sorted(data_files)\n",
    "\n",
    "missing_imus = []\n",
    "res = {}\n",
    "\n",
    "for filepath in data_files:\n",
    "    df = pd.read_csv(filepath, header=None)\n",
    "    # Match the relevant EMG columns to the patient name in the filepath\n",
    "    emg_columns = [v for k, v in patient_emg_columns.items() if k in filepath][0]\n",
    "    header = [\"index\", \"timestamp\"] + eeg_columns + emg_columns + imu_options + [\"labels\"]\n",
    "    df.columns = header\n",
    "    df = df[cols]\n",
    "\n",
    "    # Convert timestamps to offsets in milliseconds\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    t0 = df['timestamp'][0]\n",
    "    df['timestamp'] = df['timestamp'].apply(lambda x: (x - t0).value / 1e6)  # timedelta.value is in nanoseconds\n",
    "\n",
    "    # Collect stats\n",
    "    stats = {}\n",
    "    for col in cols:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        ub = df[col].max()\n",
    "        lb = df[col].min()\n",
    "        # Skip columns with no signal\n",
    "        if mean == std == ub == lb == 0:\n",
    "            continue\n",
    "        stats[col] = {\n",
    "            \"mean\": mean,\n",
    "            \"std\": std,\n",
    "            \"min\": lb,\n",
    "            \"max\": ub,\n",
    "            \"N\": len(df)\n",
    "        }\n",
    "    # Some patients might not have all the IMU data points\n",
    "    num_imus = len([k for k in stats.keys() if \"accel_x\" in k])\n",
    "    if num_imus < 4:\n",
    "        missing_imus.append(filepath)\n",
    "\n",
    "    res[filepath] = (df, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/trevoryu/Code/data/FOG_data/001/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/001/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/001/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/001/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/002/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/002/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/002/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/002/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/003/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/003/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/003/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/003/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/004/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/004/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/004/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/004/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/004/task_5.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/005/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/005/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/005/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/005/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/006/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/006/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/006/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/006/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/007/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/007/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/007/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/007/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_5.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/011/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/011/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/011/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/011/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/012/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/012/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/012/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/012/task_4.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subjects 1, 2, 3, 4, 5, 6, 7, 11, 12 are missing some IMU data\n",
    "missing_imus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = [f\"/Users/trevoryu/Code/data/FOG_data/0{i}/task_1.txt\" for i in [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"11\", \"12\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': {'mean': 180500.0,\n",
       "  'std': 104212.58961373141,\n",
       "  'min': 0.0,\n",
       "  'max': 361000.0,\n",
       "  'N': 180501},\n",
       " 'labels': {'mean': 0.3628788760173074,\n",
       "  'std': 0.48083165269348327,\n",
       "  'min': 0,\n",
       "  'max': 1,\n",
       "  'N': 180501},\n",
       " 'emg_right_ta': {'mean': -0.22234779862715442,\n",
       "  'std': 2969.014416102385,\n",
       "  'min': -5869.0,\n",
       "  'max': 6117.0,\n",
       "  'N': 180501},\n",
       " 'emg_left_ta': {'mean': 0.27152204142913333,\n",
       "  'std': 934.6166008136009,\n",
       "  'min': -4060.5,\n",
       "  'max': 5477.5,\n",
       "  'N': 180501},\n",
       " 'emg_right_gs': {'mean': -1.6449437953252337,\n",
       "  'std': 3099.037376267388,\n",
       "  'min': -5613.5,\n",
       "  'max': 5744.5,\n",
       "  'N': 180501},\n",
       " 'ecg': {'mean': -1.1736749380889857,\n",
       "  'std': 2571.6215763091022,\n",
       "  'min': -5126.0,\n",
       "  'max': 6339.5,\n",
       "  'N': 180501},\n",
       " 'eog': {'mean': 0.17161123761087196,\n",
       "  'std': 44.845060451814426,\n",
       "  'min': -391.5,\n",
       "  'max': 302.5,\n",
       "  'N': 180501},\n",
       " 'left_shank_accel_x': {'mean': 8377.38501041035,\n",
       "  'std': 4407.496655823841,\n",
       "  'min': -36396.87926295932,\n",
       "  'max': 38340.70295044864,\n",
       "  'N': 180501},\n",
       " 'left_shank_accel_y': {'mean': -1393.771096419368,\n",
       "  'std': 5231.698653840594,\n",
       "  'min': -40896.00221040318,\n",
       "  'max': 41149.80301756403,\n",
       "  'N': 180501},\n",
       " 'left_shank_accel_z': {'mean': -1319.8806217161666,\n",
       "  'std': 2724.8471753098834,\n",
       "  'min': -22963.0,\n",
       "  'max': 35028.10251686858,\n",
       "  'N': 180501},\n",
       " 'left_shank_gyro_x': {'mean': -112.42416611483645,\n",
       "  'std': 1319.185522466977,\n",
       "  'min': -10334.550416045991,\n",
       "  'max': 9246.0502017108,\n",
       "  'N': 180501},\n",
       " 'left_shank_gyro_y': {'mean': -9.026401532061614,\n",
       "  'std': 712.2955956181936,\n",
       "  'min': -8191.9038623035485,\n",
       "  'max': 12110.335928923616,\n",
       "  'N': 180501},\n",
       " 'left_shank_gyro_z': {'mean': -15.056879290344554,\n",
       "  'std': 2642.5138578034394,\n",
       "  'min': -10136.700071539182,\n",
       "  'max': 9515.015069988378,\n",
       "  'N': 180501},\n",
       " 'waist_accel_x': {'mean': 8089.461582318056,\n",
       "  'std': 938.7579594351621,\n",
       "  'min': 176.08219091889077,\n",
       "  'max': 21212.94672579452,\n",
       "  'N': 180501},\n",
       " 'waist_accel_y': {'mean': 311.2713401559744,\n",
       "  'std': 1025.587962860971,\n",
       "  'min': -14306.547890537197,\n",
       "  'max': 13874.0,\n",
       "  'N': 180501},\n",
       " 'waist_accel_z': {'mean': 1517.1002465673773,\n",
       "  'std': 901.5884320815549,\n",
       "  'min': -3534.537768908777,\n",
       "  'max': 8436.584732313735,\n",
       "  'N': 180501},\n",
       " 'waist_gyro_x': {'mean': -47.87078382945763,\n",
       "  'std': 572.9923888326769,\n",
       "  'min': -3556.039190778901,\n",
       "  'max': 4082.949661052513,\n",
       "  'N': 180501},\n",
       " 'waist_gyro_y': {'mean': 57.314243652562816,\n",
       "  'std': 310.86523537286376,\n",
       "  'min': -6333.369664950802,\n",
       "  'max': 2209.0,\n",
       "  'N': 180501},\n",
       " 'waist_gyro_z': {'mean': 8.422848586637242,\n",
       "  'std': 267.0633847846529,\n",
       "  'min': -2197.93592357887,\n",
       "  'max': 2466.6261573008164,\n",
       "  'N': 180501},\n",
       " 'arm_accel_x': {'mean': 7800.061455610917,\n",
       "  'std': 1210.581594383096,\n",
       "  'min': -7771.2674912175025,\n",
       "  'max': 18702.659445292906,\n",
       "  'N': 180501},\n",
       " 'arm_accel_y': {'mean': 2607.1778200502677,\n",
       "  'std': 1027.0236638856763,\n",
       "  'min': -11804.000000000004,\n",
       "  'max': 25965.0,\n",
       "  'N': 180501},\n",
       " 'arm_accel_z': {'mean': -276.66869973671646,\n",
       "  'std': 1352.6226533405934,\n",
       "  'min': -22394.57622419565,\n",
       "  'max': 27700.00000000001,\n",
       "  'N': 180501},\n",
       " 'arm_gyro_x': {'mean': 19.976823111699428,\n",
       "  'std': 807.3143123307507,\n",
       "  'min': -16969.6784314407,\n",
       "  'max': 18749.0,\n",
       "  'N': 180501},\n",
       " 'arm_gyro_y': {'mean': 50.531837680097446,\n",
       "  'std': 404.29072484997306,\n",
       "  'min': -5476.962962408816,\n",
       "  'max': 9079.7155578645,\n",
       "  'N': 180501},\n",
       " 'arm_gyro_z': {'mean': 8.103528756451876,\n",
       "  'std': 518.6440338522049,\n",
       "  'min': -4676.5430499038,\n",
       "  'max': 6131.977915884248,\n",
       "  'N': 180501},\n",
       " 'arm_skin_conductance': {'mean': 1762.3803746249553,\n",
       "  'std': 71.72893515136566,\n",
       "  'min': 1320.8811207155973,\n",
       "  'max': 1833.1851162165387,\n",
       "  'N': 180501}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The readme document says that if 2 IMUs were used, then they would be on the left tibia and the wrist\n",
    "# However, there are subjects with (arm + L-shank), (arm + R-shank), (arm + R-shank + L-shank) and other combos\n",
    "res[test_files[0]][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_points = sum([len(df) for df, stats in res.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6211056"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_4.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_1/task_5.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_1.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_2.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_3.txt',\n",
       " '/Users/trevoryu/Code/data/FOG_data/008/OFF_2/task_4.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_8_files = [k for k in res.keys() if \"008\" in k]\n",
    "subject_8_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered, mostly raw dataframes as csv files\n",
    "save_path = \"/Users/trevoryu/Code/syde_599/data/raw_fog_data/\"\n",
    "raw_stats = {}\n",
    "for filepath, (df, stats) in res.items():\n",
    "    # Consolidate all the subject 8 data\n",
    "    # Remove the splits\n",
    "    if \"OFF_1/\" in filepath:\n",
    "        filepath = filepath.replace(\"OFF_1/\", \"\")\n",
    "    if \"OFF_2/\" in filepath:\n",
    "        filepath = filepath.replace(\"OFF_2/\", \"\")\n",
    "        # Add 5 to the OFF_2 task numbers\n",
    "        old_num = int(filepath[-5])\n",
    "        new_num = old_num + 5\n",
    "        filepath = filepath.replace(f\"task_{old_num}\", f\"task_{new_num}\")\n",
    "    # Make new filename, e.g. \"001_task_1.csv\"\n",
    "    new_filename = \"_\".join(filepath.split(\"/\")[-2:])\n",
    "    new_filename = new_filename.replace(\".txt\", \".csv\").replace(\"/\", \"_\")\n",
    "    \n",
    "    # Store the raw stats to save for later\n",
    "    raw_stats[new_filename] = stats\n",
    "\n",
    "    df.to_csv(save_path + new_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(save_path + \"raw_stats.pkl\", \"wb\") as f:\n",
    "    pickle.dump(raw_stats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by subtracting the mean and dividing by the standard deviateogn\n",
    "# 0s will stay the same, they weren't recorded in stats anyways\n",
    "# Save as csv files\n",
    "save_path = \"/Users/trevoryu/Code/syde_599/data/norm_fog_data/\"\n",
    "\n",
    "for filepath, (df, stats) in res.items():\n",
    "    # Consolidate all the subject 8 data\n",
    "    # Remove the splits\n",
    "    if \"OFF_1/\" in filepath:\n",
    "        filepath = filepath.replace(\"OFF_1/\", \"\")\n",
    "    if \"OFF_2/\" in filepath:\n",
    "        filepath = filepath.replace(\"OFF_2/\", \"\")\n",
    "        # Add 5 to the OFF_2 task numbers\n",
    "        old_num = int(filepath[-5])\n",
    "        new_num = old_num + 5\n",
    "        filepath = filepath.replace(f\"task_{old_num}\", f\"task_{new_num}\")\n",
    "    # Make new filename, e.g. \"001_task_1.csv\"\n",
    "    new_filename = \"_\".join(filepath.split(\"/\")[-2:])\n",
    "    new_filename = new_filename.replace(\".txt\", \".csv\").replace(\"/\", \"_\")\n",
    "    \n",
    "    for col in stats:\n",
    "        # Don't normalize timestamp or labels\n",
    "        if col in [\"timestamp\", \"labels\"]:\n",
    "            continue\n",
    "        df[col] = (df[col] - stats[col][\"mean\"]) / stats[col][\"std\"]\n",
    "\n",
    "    df.to_csv(save_path + new_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('datasci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fddaefb328894158b465f763a80d93613a8dda1c2f29f2bb5673421f61ac7a4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
