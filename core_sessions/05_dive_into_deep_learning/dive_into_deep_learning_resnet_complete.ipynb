{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer perceptron activity\n",
    "\n",
    "In this activity, you will make a multi-layer perceptron (MLP) model in the PyTorch deep learning package to perform classification of hand-written digits in the classic MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Main torch import for torch tensors\n",
    "import torch.nn as nn  # Neural network module for building deep learning models\n",
    "import torch.nn.functional as F  # Functional module, includes activation functions\n",
    "import torch.optim as optim  # Optimization module\n",
    "import torchvision  # Vision / image processing package built on top of torch\n",
    "\n",
    "from matplotlib import pyplot as plt  # Plotting and visualization\n",
    "from sklearn.metrics import accuracy_score  # Computing accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Colab\n",
    "# DATA_PATH = \"/content/datafiles\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)\n",
    "DATA_PATH = \"/Users/trevoryu/Code/data/mnist/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common practice to normalize input data to neural networks (0 mean, unit variance)\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),  # All inputs to PyTorch neural networks must be torch.Tensor\n",
    "    torchvision.transforms.Normalize(mean=0.1307, std=0.3081)  # Subtracts mean and divides by std. Note that the raw data is between [0, 1]\n",
    "])\n",
    "\n",
    "# Download the MNIST data and lazily apply the transformation pipeline\n",
    "train_data = torchvision.datasets.MNIST(DATA_PATH, train=True, download=True, transform=transform)\n",
    "test_data = torchvision.datasets.MNIST(DATA_PATH, train=False, download=True, transform=transform)\n",
    "\n",
    "# Setup data loaders\n",
    "# Note: Iterating through the dataloader yields batches of (inputs, targets)\n",
    "# where inputs is a torch.Tensor of shape (B, 1, 28, 28) and targets is a torch.Tensor of shape (B,)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 5, figsize=(5, 6))\n",
    "\n",
    "plot_images = []\n",
    "plot_labels = []\n",
    "\n",
    "for i, ax in enumerate(axs.flatten(), start=1000):\n",
    "    (image, label) = test_data[i]\n",
    "\n",
    "    # Save this data for later\n",
    "    plot_images.append(image)\n",
    "    plot_labels.append(label)\n",
    "\n",
    "    # Plot each image\n",
    "    ax.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plot_images = torch.cat(plot_images)  # Combine all the images into a single batch for later\n",
    "\n",
    "print(f\"Each image is a torch.Tensor and has shape {image.shape}.\")\n",
    "print(f\"The labels are the integers 0 to 9, representing the digits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. Define the ResNetV2 Block\n",
    "\n",
    "ResNet-V1: [Deep Residual Learning for Image Recognition (He et al., 2015)](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "\n",
    "ResNet-V2: [Identity Mappings in Deep Residual Networks (He et al., 2016)](https://arxiv.org/pdf/1603.05027.pdf)\n",
    "- BN-ReLU-Conv-BN-ReLU-Conv\n",
    "- First conv does stride (spatial downsampling) and channel changes\n",
    "- Input: (B, C_in, H, W)\n",
    "- Output: (B, C_out, H/stride, W/stride)\n",
    "\n",
    "Relevant documentation:\n",
    "\n",
    "- [PyTorch nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
    "\n",
    "- [PyTorch nn.BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#batchnorm2d)\n",
    "\n",
    "- [PyTorch nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        conv_kwargs = {\n",
    "            \"kernel_size\": (3, 3),\n",
    "            \"padding\": 1,  # To ensure 3x3 conv does not reduce image size. padding=1 also works\n",
    "            \"bias\": False\n",
    "        }\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.channels = channels\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        # This conv is in_channels -> channels and applies stride\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=channels, stride=stride, **conv_kwargs)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        # This conv is channels -> channels\n",
    "        self.conv2 = nn.Conv2d(in_channels=channels, out_channels=channels, **conv_kwargs)\n",
    "    \n",
    "    def strided_identity(self, x):\n",
    "        # Downsample with 'nearest' method (this is striding if dims are divisible by stride)\n",
    "        # Equivalently x = x[:, :, ::stride, ::stride].contiguous()\n",
    "        if self.stride != 1:\n",
    "            x = F.interpolate(x, mode='nearest', scale_factor=(1/self.stride))\n",
    "        # Create padding tensor for extra channels\n",
    "        if self.channels != self.in_channels:\n",
    "            (b, c, h, w) = x.shape\n",
    "            num_pad_channels = self.channels - self.in_channels\n",
    "            pad = torch.zeros((b, num_pad_channels, h, w), device=x.device)\n",
    "            # Append padding to the downsampled identity\n",
    "            x = torch.cat((x, pad), dim=1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Compute residual\n",
    "        identity = self.strided_identity(x)\n",
    "        # TODO: Computer processing pathway\n",
    "        z = self.bn1(x)\n",
    "        z = self.relu(z)\n",
    "        z = self.conv1(z)\n",
    "        z = self.bn2(z)\n",
    "        z = self.relu(z)\n",
    "        z = self.conv2(z)\n",
    "        # TODO: Add residual and return result\n",
    "        out = identity + z\n",
    "        return out\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs are of shape (B, 1, 28, 28) and we expect an output tensor of shape (B, 32, 28, 28)\n",
    "block = ResidualBlock(1, 32)\n",
    "x = torch.randn(2, 1, 28, 28)\n",
    "z = block(x)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs are of shape (B, 32, 28, 28) and we expect an output tensor of shape (B, 64, 14, 14)\n",
    "block = ResidualBlock(32, 64, stride=2)\n",
    "x = torch.randn(2, 32, 28, 28)\n",
    "z = block(x)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b. Define CNN architecture\n",
    "\n",
    "Input layer:\n",
    "- Conv(1, 32)\n",
    "- BatchNorm\n",
    "\n",
    "Processing layers:\n",
    "1. ResNetBlock(32, 32)\n",
    "2. ResNetBlock(32, 32)\n",
    "3. ResNetBlock(32, 64, s=2)\n",
    "4. ResNetBlock(64, 64)\n",
    "5. ResNetBlock(64, 128, s=2)\n",
    "6. ResNetBlock(128, 128)\n",
    "\n",
    "Output layers:\n",
    "- AdaptiveAveragePooling\n",
    "- Linear(49, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetV2(nn.Module):\n",
    "    def __init__(self, in_channels=1, in_shape=(28,28)):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.in_shape = in_shape\n",
    "        # Input layers\n",
    "        self.input_conv = nn.Conv2d(in_channels, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.input_bn = nn.BatchNorm2d(32)\n",
    "        # Processing blocks\n",
    "        self.layer_1 = ResidualBlock(32, 32)\n",
    "        self.layer_2 = ResidualBlock(32, 32)\n",
    "        self.layer_3 = ResidualBlock(32, 64, stride=2)\n",
    "        self.layer_4 = ResidualBlock(64, 64)\n",
    "        self.layer_5 = ResidualBlock(64, 128, stride=2)\n",
    "        self.layer_6 = ResidualBlock(128, 128)\n",
    "        # Output layers\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.output_layer = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: Tensor of shape (B, 1, 28, 28)\n",
    "        :returns: Tensor of shape (B, 10)\n",
    "        \"\"\"\n",
    "        # Input layers\n",
    "        x = self.input_conv(x)\n",
    "        x = self.input_bn(x)\n",
    "        # Processing blocks\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.layer_4(x)\n",
    "        x = self.layer_5(x)\n",
    "        x = self.layer_6(x)\n",
    "        # Output layers\n",
    "        x = self.pool(x)\n",
    "        x = x.squeeze()\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNetV2()\n",
    "inputs = torch.randn(2, 1, 28, 28)\n",
    "outputs = model(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup optimizer and loss function\n",
    "\n",
    "The current standard optimizer in deep learning is the Adam optimizer. Use a learning rate of $1\\times 10^{-2}$. \n",
    "\n",
    "The task we are performing is multiclass classification (10 independent classes, one for each digit). The loss function to use for this task is cross entropy loss.\n",
    "\n",
    "Relevant documentation:\n",
    "- [PyTorch optimizers](https://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "- [PyTorch loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Instantiate your model and setup the optimizer\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "model = ResNetV2().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Setup training loop\n",
    "\n",
    "During the training loop, we perform the following steps:\n",
    "\n",
    "1. Fetch the next batch of inputs and targets from the dataloader\n",
    "2. Zero the parameter gradients\n",
    "3. Compute the model output predictions from the inputs\n",
    "4. Compute the loss between the model outputs and the targets\n",
    "5. Compute the parameter gradients with backpropagation\n",
    "6. Perform a gradient descent step with the optimizer to update the model parameters\n",
    "\n",
    "Relevant documentation:\n",
    "- [PyTorch optimization step](https://pytorch.org/docs/stable/optim.html#taking-an-optimization-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_fn, optimizer, device=\"cpu\", epoch=-1):\n",
    "    \"\"\"\n",
    "    Trains a model for one epoch (one pass through the entire training data).\n",
    "\n",
    "    :param model: PyTorch model\n",
    "    :param train_loader: PyTorch Dataloader for training data\n",
    "    :param loss_fn: PyTorch loss function\n",
    "    :param optimizer: PyTorch optimizer, initialized with model parameters\n",
    "    :kwarg epoch: Integer epoch to use when printing loss and accuracy\n",
    "    :returns: Accuracy score\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()  # Set model in training mode\n",
    "    for i, (inputs, targets) in enumerate(train_loader):  # 1. Fetch next batch of data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # 2. Zero parameter gradients\n",
    "        outputs = model(inputs)  # 3. Compute model outputs\n",
    "        loss = loss_fn(outputs, targets)  # 4. Compute loss between outputs and targets\n",
    "        loss.backward()  # 5. Backpropagation for parameter gradients\n",
    "        optimizer.step()  # 6. Gradient descent step\n",
    "\n",
    "        # Track some values to compute statistics\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs.cpu(), dim=-1)  # Take the class with the highest output as the prediction\n",
    "        all_predictions.extend(preds.tolist())\n",
    "        all_targets.extend(targets.tolist())\n",
    "\n",
    "        # Print some statistics every 100 batches\n",
    "        if i % 100 == 0:\n",
    "            running_loss = total_loss / (i + 1)\n",
    "            print(f\"Epoch {epoch + 1}, batch {i + 1}: loss = {running_loss:.2f}\")\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_predictions)\n",
    "\n",
    "    # Print average loss and accuracy\n",
    "    print(f\"Epoch {epoch + 1} done. Average train loss = {total_loss / len(train_loader):.2f}, average train accuracy = {acc * 100:.3f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In testing, we don't need to compute gradients or do an optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_fn, device=\"cpu\", epoch=-1):\n",
    "    \"\"\"\n",
    "    Tests a model for one epoch of test data.\n",
    "\n",
    "    Note:\n",
    "        In testing and evaluation, we do not perform gradient descent optimization, so steps 2, 5, and 6 are not needed.\n",
    "        For performance, we also tell torch not to track gradients by using the `with torch.no_grad()` context.\n",
    "\n",
    "    :param model: PyTorch model\n",
    "    :param test_loader: PyTorch Dataloader for test data\n",
    "    :param loss_fn: PyTorch loss function\n",
    "    :kwarg epoch: Integer epoch to use when printing loss and accuracy\n",
    "\n",
    "    :returns: Accuracy score\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set model in evaluation mode\n",
    "    for i, (inputs, targets) in enumerate(test_loader):  # 1. Fetch next batch of data\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)  # 3. Compute model outputs\n",
    "            loss = loss_fn(outputs, targets)  # 4. Compute loss between outputs and targets\n",
    "\n",
    "            # Track some values to compute statistics\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs.cpu(), dim=-1)  # Take the class with the highest output as the prediction\n",
    "            all_predictions.extend(preds.tolist())\n",
    "            all_targets.extend(targets.tolist())\n",
    "\n",
    "    acc = accuracy_score(all_targets, all_predictions)\n",
    "\n",
    "    # Print average loss and accuracy\n",
    "    print(f\"Epoch {epoch + 1} done. Average test loss = {total_loss / len(test_loader):.2f}, average test accuracy = {acc * 100:.3f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = []\n",
    "test_metrics = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # TODO: Fill in the rest of the arguments to the train and test functions\n",
    "    train_acc = train(model, train_loader, loss_fn, optimizer, device=DEVICE, epoch=epoch)\n",
    "    test_acc = test(model, test_loader, loss_fn, device=DEVICE, epoch=epoch)\n",
    "\n",
    "    train_metrics.append(train_acc)\n",
    "    test_metrics.append(test_acc)\n",
    "    #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visually compare the model predictions\n",
    "\n",
    "We will lastly see the trained model's predictions on the 20 examples we visualized in the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the plot_images\n",
    "model.eval()\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    plot_outputs = model(plot_images)\n",
    "    plot_preds = torch.argmax(plot_outputs, dim=-1)\n",
    "\n",
    "# Plot and show the labels\n",
    "fig, axs = plt.subplots(4, 5, figsize=(7, 8))\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    image = plot_images[i]\n",
    "    label = plot_labels[i]\n",
    "    pred = plot_preds[i]\n",
    "\n",
    "    ax.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    ax.set_title(f\"Prediction: {pred}\\nLabel: {label}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "xs = 1 + torch.arange(NUM_EPOCHS)\n",
    "plt.plot(xs, train_metrics, \"o-\", label=\"Train accuracy\")\n",
    "plt.plot(xs, test_metrics, \"o-\", label=\"Test accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
