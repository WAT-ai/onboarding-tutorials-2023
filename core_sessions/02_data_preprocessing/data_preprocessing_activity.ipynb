{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Preprocessing for Spotify Emotion Classification\n",
    "\n",
    "Data from Kaggle ([link](https://www.kaggle.com/datasets/abdullahorzan/moodify-dataset))\n",
    "\n",
    "Machine learning engineers are looking to classify songs into one of four categories:\n",
    "Sad (0), happy (1), energetic (2), and calm (3). For each song, the following features have been collected.\n",
    "\n",
    "Acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.\n",
    "\n",
    "Danceability: Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "\n",
    "Duration: Duration of the song in milliseconds. This feature has been log-transformed to make the distribution more reasonable.\n",
    "\n",
    "Energy: Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n",
    "\n",
    "Instrumentalness: Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "\n",
    "Liveness: Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides a strong likelihood that the track is live.\n",
    "\n",
    "Loudness: the overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing the relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typically range between -60 and 0 db.\n",
    "\n",
    "Speechiness: Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audiobook, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n",
    "\n",
    "Valence: A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "\n",
    "Tempo: The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, the tempo is the speed or pace of a given piece and derives directly from the average beat duration."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uncomment and run this line if working in Google Colab."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/WAT-ai/onboarding-tutorials-2023"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DATA_PATH = '/content/onboarding-tutorials-2023/core_sessions/data/'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "with open(DATA_PATH+\"data_preprocessing_activity.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# For convenience, assume `df` is training data\n",
    "df = data[\"df_train\"]\n",
    "\n",
    "# You will not be modifying df_test in this activity\n",
    "df_test = data[\"df_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data pre-processing activity\n",
    "In this activity, you will be applying the pre-processing techniques learned in the code-along portion of the workshop to prepare a dataset for a ML model.\n",
    "\n",
    "The training dataset has been intentionally modifed to simulate issues found in real world datasets. Your task is to apply the relevant pre-processing techniques to the training dataset. The test dataset can be assumed to be a model of appropriate processing applied, and analyzing it may help inform how to proceed.\n",
    "\n",
    "Both datasets are provided as pandas dataframes, and you will only need to apply operations to the training dataframe to complete the activity. The ML portion under the Testing heading does not need to be touched.\n",
    "\n",
    "The script will not run successfully until you:\n",
    "1. Check for and remove unnecessary features\n",
    "2. Convert the labels from categorical to numeric\n",
    "3. Drop or interpolate missing values\n",
    "\n",
    "To improve the performance of the model on the test dataset, we also recommend that you:\n",
    "1. Check for and remove outliers\n",
    "2. Scale the data to the same statistics as the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "<details>\n",
    "<summary> Removing unecessary columns </summary>\n",
    "Examine the columns names. Which ones clearly do not belong? Once you've found them, drop the columns from the dataset.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> Converting labels to categorical </summary>\n",
    "Make a dictionary with a mapping of the text labels to the class numbers. You can use <code>df[col].apply(func, inplace=True)</code> to apply a simple mapping function to the values.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> Dealing with NaN values </summary>\n",
    "Use <code>df.isna().sum(axis=0)</code> to find which columns might contain NaN values. You can interpolate them or drop them.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Removing outliers</summary>\n",
    "Adapt the code from the code-along to plot the distributions of the relevant columns. What are the expected value ranges for these columns? Use a simple threshold rule to remove any unwanted values from columns that appear to have outlier values.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>Scaling data</summary>\n",
    "What is the mean and standard deviation of each of the feature columns in the test dataset? What kind of scaling should we apply to the training dataset to match that? Remember, we only scale the features, not the labels!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show testing data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical according to the description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Remove outliers heuristically\n",
    "outlier_potential_columns = ['acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'speechiness', 'valence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Scale the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test your model\n",
    "Run the cells below to test if the data pre-processing applied was appropriate. Assign a numpy array of training features to `X_train` and a vector of labels to `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve training data\n",
    "X_train = None\n",
    "y_train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT MODIFY ###\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Retrieve test data\n",
    "X_test = df_test.drop(\"labels\", axis=1).values\n",
    "y_test = df_test[\"labels\"].values\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Testing accuracy:  {test_acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
