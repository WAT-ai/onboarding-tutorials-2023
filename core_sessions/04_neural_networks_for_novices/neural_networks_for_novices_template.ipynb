{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Neural Networks for Novices\n",
    "Prerequisites:\n",
    "- Python experience, including a basing understanding of python syntax, loops, conditional statements, functions, and data types in python\n",
    "- Some background in numerical computing - MATLAB, R, numpy, or similar, and an understanding of vectors, matrices, and relevant linear algebra concepts\n",
    "- An understanding of model selection, train/test split, performance metrics and other concepts covered in the session on Classical Machine Learning\n",
    "\n",
    "Goals for this session:\n",
    "- Examine deep learning concepts such as tensors, tensor operations, gradient descent, and backpropagation\n",
    "- Define and discuss hyperparameters in the context of deep learning models, including learning rate, batch size, epochs, layers, hidden units, optimizers, and activation functions\n",
    "- Interpret loss and accuracy curves to identify overfitting during the training process\n",
    "- Apply this knowledge to a real-world dataset using Tensorflow\n",
    "\n",
    "Tensorflow documentation: [https://www.tensorflow.org/api_docs/python/tf](https://www.tensorflow.org/api_docs/python/tf)\n",
    "\n",
    "Keras documentation: [https://www.tensorflow.org/guide/keras](https://www.tensorflow.org/guide/keras)\n",
    "\n",
    "Tip: For faster training times, set your runtime to T4 GPU under `Runtime > Change runtime type`. Luckily, Tensorflow conveniently manages simple GPU use cases like this under the hood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "SEED = 100\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab\n",
    "DATA_PATH = \"/content/datafiles\"\n",
    "SAVE_PATH = \"/content/models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain dataset\n",
    "The dataset can be downloaded using Tensorflow datasets conveniently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_dataset, val_dataset, test_dataset), ds_info = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=[\"train[0:50_000]\", \"train[-10_000:]\", \"test\"],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    "    data_dir=DATA_PATH\n",
    ")\n",
    "list(map(len, [train_dataset, val_dataset, test_dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot, y_plot = tfds.load(\n",
    "    \"mnist\",\n",
    "    split=\"test[1000:1020]\",\n",
    "    shuffle_files=False,\n",
    "    as_supervised=True,\n",
    "    data_dir=DATA_PATH,\n",
    "    batch_size=-1\n",
    ")\n",
    "# x_plot dtype is int8, scale between [0, 1] in float32 dtype for later\n",
    "x_plot = x_plot / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_plot has shape (B, H, W, C)\n",
    "x_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 5, figsize=(5, 6))\n",
    "\n",
    "plot_images = []\n",
    "plot_labels = []\n",
    "\n",
    "for ax, image, label in zip(axs.flatten(), x_plot, y_plot):\n",
    "    # Save this data for later\n",
    "    plot_images.append(tf.expand_dims(image, 0))\n",
    "    plot_labels.append(label)\n",
    "\n",
    "    # Plot each image\n",
    "    ax.imshow(tf.squeeze(image), cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "plot_images = tf.concat(plot_images, axis=0)  # Combine all the images into a single batch for later\n",
    "\n",
    "print(f\"Each image is a tf.Tensor and has shape {image.shape}.\")\n",
    "print(f\"The labels are the integers 0 to 9, representing the digits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data into tensors\n",
    "Loading from `tfds` already returns tensors, so if your data comes from other sources, you would need to do this. However, our data comes in `uint8` datatype, but most neural networks expect `float32`. Additionally, neural networks prefer data that comes from a random normal distribution, or scaled to between [-1, 1] or [0, 1]. We can scale the data easily to [0, 1] by dividing by 255, the maximum value of a `uint8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess input data to neural network\n",
    "    :param x: tf.Tensor image batch, of shape (B, 28, 28, 1)\n",
    "    :param y: tf.Tensor labels, of shape (B,)\n",
    "\n",
    "    :returns: (x, y), processed inputs of shapes ((B, 784), (B,))\n",
    "    \"\"\"\n",
    "    # Rescale the data\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing to all the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model architecture\n",
    "Conveniently, Keras allows us to define a model as a sequence of layers. For a simple multi-layer perceptron, this is perfect, although more complex architectures can be made too using a similar API to PyTorch (come to Dive Into Deep Learning to learn more!). Keras also has a `Dense` layer that implements both the linear weight matrix, additive bias, and activation into one layer. Since the multi-layer perceptron is built of these three things, we can just use `Dense` layers. Note that since our inputs come in shape (28, 28, 1), we should flatten them first to a vector of length (784,) before passing them to the `Dense` layers.\n",
    "\n",
    "Note that the output of the model will the log odds (or logits) of predicting each of the 10 classes. The index of the output with the highest probability is the class that would be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # Dense layer of 2048 units\n",
    "    # Dense layer of 512 units\n",
    "    # Dense layer of 128 units\n",
    "    # Output layer, 10 units, no activation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our model on the plotting datapoints. The output should be shape (B, n_classes) = (20, 10)\n",
    "logits = model(x_plot)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select hyperparameters\n",
    "We'll use a batch size of 128, train for 20 epochs, and use an optimizer learning rate of 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = None\n",
    "EPOCHS = None\n",
    "LEARNING_RATE = None\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loss function, `SparseCategoricalCrossentropy(from_logits=True)` implements softmax efficiently in the loss calculation, so we don't need to include a final softmax activation in the last layer. The corresponding metric for this classification problem is `SparseCategoricalAccuracy`. \n",
    "\n",
    "For the optimizer, `Adam` is a typical default deep learning optimizer and is a good starting point for many problems.\n",
    "\n",
    "For the datasets, we need to batch and shuffle the training dataset. For the validation and test datasets, we don't need to shuffle, but we should still batch them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = None\n",
    "metrics = [None]\n",
    "\n",
    "optimizer = None\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(buffer_size=train_dataset.cardinality(), seed=SEED).batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.cache().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "test_dataset = test_dataset.cache().batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify, we can compute the loss over the test images we showed earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function(y_plot, logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tensorflow, we compile the model with the optimizer, loss, and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow has a convient training API with the `fit` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `history` object returned from `model.fit()` contains a lot of metrics that Tensorflow automatically records. We can plot them to visualize the training curves and see how well the model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "labels = {\n",
    "    \"loss\": \"Train loss\",\n",
    "    \"sparse_categorical_accuracy\": \"Train accuracy\",\n",
    "    \"val_loss\": \"Validation loss\",\n",
    "    \"val_sparse_categorical_accuracy\": \"Validation accuracy\"\n",
    "}\n",
    "\n",
    "epochs = np.arange(EPOCHS) + 1\n",
    "\n",
    "for key, metric in history.history.items():\n",
    "    if \"loss\" in key:\n",
    "        epochs = np.arange(len(metric)) + 1\n",
    "        axs[0].plot(epochs, metric, label=labels[key])\n",
    "    else:\n",
    "        axs[1].plot(epochs, metric, label=labels[key])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "\n",
    "axs[0].set_title(\"Loss\")\n",
    "# axs[0].set_ylim(-0.05, 0.5)\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "plt.suptitle(\"Training curves\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to have overfit by the end of 20 epochs. The validation loss is going up, and the accuracy is fluctuating. The model's performance is a little based on chance, depending on where it was after the 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on the test set\n",
    "\n",
    "We should always test our model on the testing dataset. Especially if we do hyperparameter tuning, it is not sufficient to just use two datasets, since we might adjust hyperparameters that best fit the validation data, but not some other realworld / held out data.\n",
    "\n",
    "If we have labels, we can score the model with `model.evaluate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = None\n",
    "test_accuracy = None\n",
    "print(f\"Test loss: {test_loss:.3f}\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only have inputs, then we should use `model.predict()` instead. Remember that the model returns log probability scores (logits). So to obtain the class, we should use `argmax` to find the index of the most likely (highest probability) output neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and show the labels\n",
    "fig, axs = plt.subplots(4, 5, figsize=(7, 8))\n",
    "\n",
    "for ax, image, label, pred in zip(axs.flatten(), x_plot, y_plot, y_pred):\n",
    "    # Plot each image\n",
    "    ax.imshow(tf.squeeze(image), cmap=\"gray\")\n",
    "    ax.set_title(f\"Prediction: {pred}\\nLabel: {label}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to stop the model from overfitting?\n",
    "\n",
    "In the Dive into Deep Learning session, we'll talk more about \"regularization,\" which are techniques to stop from overfitting. But one easy one to use in Tensorflow is early stopping. Early stopping allows us to try to stop training before we get to overfitting. We can save a version of the model's parameters and load that for testing.\n",
    "\n",
    "We can implement early stopping and model checkpointing with callbacks. These are functions that are called at certain points in the training loop. Our callbacks, in particular, will be called at the end of each epoch. Depending on the performance of the model, the training procedure might stop and a version of the model's parameters might be saved.\n",
    "\n",
    "For early stopping, we need to pick a metric to monitor. We can also specify how long after the \"best\" observation of that metric we should wait until we call it quits.\n",
    "\n",
    "For model checkpointing, we also need to specify a metric to monitor. We can also specify whether to save all models, or just the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset seed\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new model and train it\n",
    "model = keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(2048, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_function,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-plot the training curves\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "labels = {\n",
    "    \"loss\": \"Train loss\",\n",
    "    \"sparse_categorical_accuracy\": \"Train accuracy\",\n",
    "    \"val_loss\": \"Validation loss\",\n",
    "    \"val_sparse_categorical_accuracy\": \"Validation accuracy\"\n",
    "}\n",
    "\n",
    "epochs = np.arange(EPOCHS) + 1\n",
    "best_ind = np.argmax(history.history[\"val_sparse_categorical_accuracy\"])\n",
    "best_acc = history.history[\"val_sparse_categorical_accuracy\"][best_ind]\n",
    "best_loss = history.history[\"val_loss\"][best_ind]\n",
    "\n",
    "for key, metric in history.history.items():\n",
    "    if \"loss\" in key:\n",
    "        epochs = np.arange(len(metric)) + 1\n",
    "        axs[0].plot(epochs, metric, label=labels[key])\n",
    "    else:\n",
    "        axs[1].plot(epochs, metric, label=labels[key])\n",
    "\n",
    "axs[0].plot(epochs[best_ind], best_loss, \"ro\")\n",
    "axs[1].plot(epochs[best_ind], best_acc, \"ro\")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "\n",
    "\n",
    "axs[0].set_title(\"Loss\")\n",
    "# axs[0].set_ylim(-0.05, 0.5)\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "plt.suptitle(\"Training curves\")\n",
    "plt.tight_layout()\n",
    "\n",
    "print(f\"Best val accuracy: {best_acc*100:.3f}%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model stopped traiing at epoch 7 when the validation accuracy was the highest and it didn't improve for the following 3 epochs. We should load this model checkpoint and check its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set with best model\n",
    "best_model = None\n",
    "checkpoint_test_loss, checkpoint_test_accuracy = None\n",
    "\n",
    "print(f\"Test loss, best model: {checkpoint_test_loss:.3f}\")\n",
    "print(f\"Test accuracy, best model: {checkpoint_test_accuracy*100:.2f}%\")\n",
    "\n",
    "print(f\"Test loss, old model: {test_loss:.3f}\")\n",
    "print(f\"Test accuracy, old model: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping helped to improve our held-out test set accuracy. In the activity, you can try to manually adjust other hyperparameters to see if you can get the performance to improve!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
